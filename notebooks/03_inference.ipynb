{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01926d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import os, glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "from utils.data import InferenceImageDataset\n",
    "from utils.models import get_efficientnetb0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "500f729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 640\n",
    "#\"negative\", \"typical\", \"indeterminate\", \"atypical\"\n",
    "#               indeterminate    negative    atypical    typical\n",
    "label_names = ['indeterminate', 'negative', 'atypical', 'typical']\n",
    "NUM_CLASSES = len(label_names)\n",
    "TEST_IMG_DIR = \"../../../Dataset/Covid19/test_full_size_jpg/test_data_jpg/*.jpg\"\n",
    "WEIGHTS_PATH = os.path.join(\"../weights\", \"best.pt\")\n",
    "TEST_IMG2STUDY_PATH = \"../../../Dataset/Covid19/test_image2study.json\"\n",
    "EXAMPLE_SUBMISSION_PATH = \"../../../Dataset/Covid19/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f40b6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "def get_test_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b65bbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = glob.glob(TEST_IMG_DIR)\n",
    "test_dataset = InferenceImageDataset(test_imgs, get_test_grayscale_transforms(IMG_SIZE), label_names)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fc2c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1263/1263 [02:53<00:00,  7.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using gpu or not\n",
    "CUDA = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if CUDA == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model = get_efficientnetb0(NUM_CLASSES, num_channels=1)\n",
    "state_dict = torch.load(WEIGHTS_PATH)\n",
    "model.load_state_dict(state_dict[\"model_state_dict\"])     \n",
    "model.to(CUDA)\n",
    "\n",
    "model.eval()\n",
    "predictions = list() \n",
    "image_paths = list()\n",
    "with torch.no_grad():\n",
    "    for X, img_paths in tqdm(test_dataloader):\n",
    "        \n",
    "        X = X.to(CUDA)\n",
    "\n",
    "        preds = model(X)\n",
    "        predictions += list(preds.argmax(axis=1).cpu().detach().numpy())\n",
    "        image_paths += list(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a666b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(EXAMPLE_SUBMISSION_PATH)\n",
    "with open(TEST_IMG2STUDY_PATH, 'r') as file:\n",
    "    image2study = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2122778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n",
      "amamk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00188a671292_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004bd59708be_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00508faccd39_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006486aa80b2_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00655178fdfc_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00a81e8f1051_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00be7de16711_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00c7a3928f0f_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00d63957bc3a_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0107f2d291d6_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0154653179fa_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>015f89ec55ea_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0241bc13eac6_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>025bfc117ff8_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>028abd3504b6_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>02ee3a9820eb_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0321bb7f84b5_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>03e0a59d9b8a_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03fc9ec0dba8_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>045783dbe7d1_study</td>\n",
       "      <td>typical 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id     PredictionString\n",
       "0   00188a671292_study  negative 1 0 0 1 1 \n",
       "1   004bd59708be_study   typical 1 0 0 1 1 \n",
       "2   00508faccd39_study  negative 1 0 0 1 1 \n",
       "3   006486aa80b2_study   typical 1 0 0 1 1 \n",
       "4   00655178fdfc_study   typical 1 0 0 1 1 \n",
       "5   00a81e8f1051_study  negative 1 0 0 1 1 \n",
       "6   00be7de16711_study   typical 1 0 0 1 1 \n",
       "7   00c7a3928f0f_study  negative 1 0 0 1 1 \n",
       "8   00d63957bc3a_study   typical 1 0 0 1 1 \n",
       "9   0107f2d291d6_study  negative 1 0 0 1 1 \n",
       "10  0154653179fa_study   typical 1 0 0 1 1 \n",
       "11  015f89ec55ea_study  negative 1 0 0 1 1 \n",
       "12  0241bc13eac6_study  negative 1 0 0 1 1 \n",
       "13  025bfc117ff8_study   typical 1 0 0 1 1 \n",
       "14  028abd3504b6_study   typical 1 0 0 1 1 \n",
       "15  02ee3a9820eb_study   typical 1 0 0 1 1 \n",
       "16  0321bb7f84b5_study  negative 1 0 0 1 1 \n",
       "17  03e0a59d9b8a_study   typical 1 0 0 1 1 \n",
       "18  03fc9ec0dba8_study  negative 1 0 0 1 1 \n",
       "19  045783dbe7d1_study   typical 1 0 0 1 1 "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_counter = dict()\n",
    "for img_path, _, label in zip(image_paths, predictions, [label_names[i] for i in predictions]):\n",
    "\n",
    "    image_id = os.path.basename(img_path).replace(\".jpg\", \"\") + \"_image\"\n",
    "    study_id = image2study[image_id]\n",
    "    \n",
    "    prediction_string = f\"{label} 1 0 0 1 1 \"\n",
    "    if study_counter.get(study_id) is None:\n",
    "        submission.loc[submission[\"id\"]==study_id, \"PredictionString\"] = prediction_string\n",
    "        study_counter[study_id] = 1\n",
    "    else:\n",
    "        print(\"amamk\") \n",
    "        submission.loc[submission[\"id\"]==study_id, \"PredictionString\"] += prediction_string\n",
    "        study_counter[study_id] += 1\n",
    "\n",
    "    \n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fcfaeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a3406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
