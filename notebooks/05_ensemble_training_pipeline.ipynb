{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prostate-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import os, glob\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from cutmix.cutmix import CutMix\n",
    "#from cutmix.utils import CutMixCrossEntropyLoss\n",
    "\n",
    "from utils.models import get_model\n",
    "from utils.data import CustomImageDataset\n",
    "from utils.log import TextDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "figured-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4 \n",
    "RESUME = False\n",
    "epochs = 30\n",
    "IMG_SIZE = 1280\n",
    "BATCH_SIZE = 4\n",
    "ACCUM_STEPS = 16\n",
    "WEIGHTS_DIR = \"../weights\"\n",
    "CUTMIX = False\n",
    "model_names = [\"resnet50\", \"cspresnet50\", \"efficientnet_b1\", \"dpn68\"]\n",
    "\n",
    "TRAIN_DATASET = \"../../../Datasets/train_test_classification_quarter_size/train\"\n",
    "VALID_DATASET = \"../../../Datasets/train_test_classification_quarter_size/valid\"\n",
    "FILENAME_SUFFIX = \"_lr1e-4\"\n",
    "\n",
    "TRAIN_DATASET += \"/*/*.jpg\"\n",
    "VALID_DATASET += \"/*/*.jpg\"\n",
    "Path(WEIGHTS_DIR).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "basic-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, Lambda\n",
    "from torchvision.transforms import ColorJitter, RandomAffine, RandomPerspective, RandomRotation, RandomErasing, RandomCrop, Grayscale\n",
    "from torchvision.transforms import RandomChoice, RandomApply\n",
    "\n",
    "def get_train_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        RandomApply([\n",
    "            ColorJitter(brightness=0.3, contrast=0.01, saturation=0.01, hue=0),\n",
    "            RandomAffine(0.1, translate=(0.04,0.04), scale=(0.04,0.04), shear=0.01, resample=2),\n",
    "            RandomCrop(30),\n",
    "            RandomPerspective(0.1)\n",
    "        ]),\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "def get_test_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "\n",
    "def show_confusion_matrix(matrix: List[List], labels: List[str]):\n",
    "    \"\"\"Display a nice confusion matrix given\n",
    "    the confusion matrix in a 2D list + list of labels (decoder)\n",
    "    \n",
    "    Args:\n",
    "        matrix: 2D array containing the values to display (confusion matrix)\n",
    "        labels: Array containing the labels (indexed by corresponding label idx)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    min_val, max_val = 0, len(labels)\n",
    "\n",
    "    for i in range(max_val):\n",
    "        for j in range(max_val):\n",
    "            c = matrix[i][j]\n",
    "            ax.text(i, j, str(int(c)), va='center', ha='center')\n",
    "\n",
    "    ax.matshow(matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "    # Set number of ticks for x-axis001\n",
    "    ax.set_xticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_xticklabels(labels, rotation='vertical', fontsize=16)\n",
    "\n",
    "    # Set number of ticks for x-axis\n",
    "    ax.set_yticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_yticklabels(labels, rotation='horizontal', fontsize=16)\n",
    "                    \n",
    "    #ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(max_val - 0.5, min_val - 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "def display_missclassified(class_to_idx: Dict[str,int], \n",
    "                           targets: List[int], \n",
    "                           predictions: List[int], \n",
    "                           images: List[np.ndarray], \n",
    "                           gridsize: Tuple[int] = (4,4)):\n",
    "    \"\"\"Display a grid with missclassified samples from test set.\n",
    "    \n",
    "    Args:\n",
    "        class_to_idx: Class to idx encoder\n",
    "        targets:      List containing all ground truths\n",
    "        predictions:  List containing all predictions\n",
    "        images:       List containing image arrays\n",
    "        gridsize:     Tuple describing the final image grid\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plot_counter = 1\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    idx_to_class = {i:label for i, label in enumerate(class_to_idx)}\n",
    "    for i in range(len(targets)):\n",
    "        if plot_counter > gridsize[0]*gridsize[1]:\n",
    "            break\n",
    "        \n",
    "        image = images[i].transpose(1, 2, 0)\n",
    "        image = ((image * std) + mean) * 255\n",
    "        image = image.astype(\"uint8\")\n",
    "    \n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = cv2.putText(image, idx_to_class[predictions[i]], (0,20), 3, 0.4, (0,0,255), 1)\n",
    "        if predictions[i] == targets[i]:\n",
    "            pass\n",
    "        else:\n",
    "            ax = fig.add_subplot(gridsize[0], gridsize[1], plot_counter)\n",
    "            ax.imshow(image)\n",
    "            plot_counter += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "incoming-ministry",
=======
   "execution_count": 22,
   "id": "84e810dc-698f-4cd6-b4e6-c54a913a2e45",
>>>>>>> d70572bd212d1d87d365bce462685f38655b6b2c
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, device, accumulate_steps=1):\n",
    "    model.train()\n",
    "    results = {\n",
    "        \"running_loss\": 0\n",
    "    }\n",
    "    t = tqdm(train_dataloader)\n",
    "    for i, (X, y) in enumerate(t):\n",
    "        \n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        results[\"running_loss\"] += loss.cpu().detach()\n",
    "        loss = loss/accumulate_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if ((i+1) % accumulate_steps) == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        t.set_description(f\"{epoch+1}/{epochs} Train: {round(float(results['running_loss'])/(i+1), 4)}\")\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_model(model, valid_dataloader, device, save_images=False):\n",
    "    results = {\n",
    "        \"running_loss\": 0,\n",
    "        \"targets\": list(),\n",
    "        \"predictions\": list()\n",
    "    }    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if save_images:\n",
    "            results[\"images\"] = list() \n",
    "            \n",
    "        t = tqdm(valid_dataloader)\n",
    "        for i, (X, y) in enumerate(t):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            preds = model(X)\n",
    "            results[\"predictions\"] += list(preds.argmax(axis=1).cpu().detach().numpy())\n",
    "            results[\"targets\"] += list(np.array(y.cpu()))\n",
    "            if save_images:\n",
    "                results[\"images\"] += list(np.array(X.cpu()))\n",
    "        \n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            results[\"running_loss\"] += loss.cpu().detach()\n",
    "            t.set_description(f\"Test: {round(float(results['running_loss']/(i+1)), 4)}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "def calculate_metrics():\n",
    "    pass\n",
    "\n",
    "class TrainingResults():\n",
    "    \n",
    "    def __init__(self, metrics):\n",
    "        self.best_results = {metric: [1e99, -1e99] for metric in metrics}\n",
    "    \n",
    "    def isHighest(self, metric, value):\n",
    "        if self.best_results[metric][1] < value:\n",
    "            self.best_results[metric][1] = value\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def isLowest(self, metric, value):\n",
    "        if self.best_results[metric][0] > value:\n",
    "            self.best_results[metric][0] = value\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def loadCheckpoint(self, checkpoint):\n",
    "        self.best_results = checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "according-exploration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indeterminate': 0, 'negative': 1, 'typical': 2, 'atypical': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_imgs = glob.glob(TRAIN_DATASET)\n",
    "valid_imgs = glob.glob(VALID_DATASET)\n",
    "\n",
    "train_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in train_imgs])\n",
    "valid_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in valid_imgs])\n",
    "class_to_idx = {label: idx for idx, label in enumerate(train_labels)}\n",
    "\n",
    "train_dataset = CustomImageDataset(train_imgs, get_test_grayscale_transforms(IMG_SIZE), train_labels)\n",
    "if CUTMIX:\n",
    "    train_dataset = CutMix(train_dataset, num_class=NUM_CLASSES, beta=1.0, prob=0.5, num_mix=3)    # this is paper's original setting for cifar.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = CustomImageDataset(valid_imgs, get_test_grayscale_transforms(IMG_SIZE), valid_labels)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suburban-garden",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth\" to /usr/src/app/.cache/torch/hub/checkpoints/resnet50_ram-a26f946b.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -3] Temporary failure in name resolution>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-592cd8155b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download all model once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/Github/classification_xray/utils/models.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_name, num_classes, input_channels, pretrained_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_chans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/factory.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_layer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexportable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexportable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_jit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_jit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \"\"\"\n\u001b[1;32m    750\u001b[0m     \u001b[0mmodel_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_create_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36m_create_resnet\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m     return build_model_with_cfg(\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0mResNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mdefault_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_cfgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/helpers.py\u001b[0m in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, default_cfg, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, pretrained_custom_load, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mload_custom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             load_pretrained(\n\u001b[0m\u001b[1;32m    447\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes_pretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/helpers.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[0;34m(model, default_cfg, num_classes, in_chans, filter_fn, strict, progress)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading pretrained weights from url ({pretrained_url})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilter_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# for backwards compat with filter fn that take one arg, try one first, the two\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r is Optional[Match[str]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# certificates in older Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"torch.hub\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'getheaders'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"
     ]
    }
   ],
   "source": [
    "# Download all model once\n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, NUM_CLASSES, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# Using gpu or not\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"Using CPU\")\n",
    "    \n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, NUM_CLASSES, 1)\n",
    "    model.to(device)\n",
    "    print(list(class_to_idx.keys()))\n",
    "\n",
    "    results_document = TextDocument(f\"{model_name}{FILENAME_SUFFIX}_results.txt\")\n",
    "    results_document.add_line(f\"acc f1 recall precision valid_loss train_loss\") \n",
    "    metrics = [\"acc\", \"f1\", \"valid_loss\"]\n",
    "    training_results = TrainingResults(metrics)\n",
    "    \n",
    "    if RESUME:\n",
    "        pass\n",
    "        #start_epoch = state_dict[\"epoch\"]\n",
    "        #optimizer_state_dict = state_dict[\"optimizer_state_dict\"]\n",
    "        \n",
    "        #model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "        #optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
    "        training_results.loadCheckpoint(state_dict[\"training_results\"])\n",
    "    else:\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        if CUTMIX:\n",
    "            criterion = CutMixCrossEntropyLoss(True)\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        # Train one epoch    \n",
    "        results = train_one_epoch(model, train_dataloader, device, accumulate_steps=ACCUM_STEPS)\n",
    "        train_loss = float(results[\"running_loss\"])\n",
    "\n",
    "\n",
    "        if epoch+1 == epochs:\n",
    "            results = evaluate_model(model, valid_dataloader, device, save_images=True)\n",
    "            images = results[\"images\"]\n",
    "        else:\n",
    "            results = evaluate_model(model, valid_dataloader, device, save_images=False)\n",
    "\n",
    "        valid_loss = float(results[\"running_loss\"])\n",
    "        acc = accuracy_score(results[\"targets\"], results[\"predictions\"])\n",
    "        f1 = f1_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        recall = recall_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        precision = precision_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        results_document.add_line(f\"{float(acc)} {float(f1)} {float(recall)} {float(precision)} {valid_loss} {train_loss}\")\n",
    "    \n",
    "        if training_results.isHighest('f1',  f1):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'training_results': training_results.best_results,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}{FILENAME_SUFFIX}_best_f1.pt\"))\n",
    "        if training_results.isHighest('acc', acc):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'training_results': training_results.best_results,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}{FILENAME_SUFFIX}_best_acc.pt\"))\n",
    "        if training_results.isLowest('valid_loss', valid_loss):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'training_results': training_results.best_results,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}{FILENAME_SUFFIX}_best_valid_loss.pt\"))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'training_results': training_results.best_results,\n",
    "            'train_dataloader': train_dataloader,\n",
    "            'test_dataloader': valid_dataloader,\n",
    "            'class_to_idx': class_to_idx\n",
    "        }, os.path.join(WEIGHTS_DIR, f\"{model_name}{FILENAME_SUFFIX}_last.pt\"))\n",
    "\n",
    "    #display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "    #show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        data = f.readlines()\n",
    "    columns = data[0].replace('\\n', '').split()\n",
    "    rows = [line.replace('\\n', '').split() for line in data[1:]]\n",
    "    for idx, row in enumerate(rows):\n",
    "        rows[idx] = [float(i) for i in row]\n",
    "    results_dict = {column: [row[i] for row in rows] for i, column in enumerate(columns)}\n",
    "    return results_dict\n",
    "\n",
    "model_names = [\"resnet50\", \"cspresnet50\", \"efficientnet_b1\", \"dpn68\"]\n",
    "fig, axs = plt.subplots(1,3, figsize=(30,10))\n",
    "for model_name in model_names:\n",
    "    txt_path = model_name + \"_results.txt\"\n",
    "    data = read_results(txt_path)\n",
    "\n",
    "    axs[0].plot(data['f1'])\n",
    "    axs[1].plot(data['acc'])\n",
    "    axs[2].plot(data['valid_loss'])\n",
    "axs[0].set_title(\"F1\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[2].set_title(\"valid_loss\")\n",
    "axs[0].legend(model_names)\n",
    "axs[1].legend(model_names)\n",
    "axs[2].legend(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-fifty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
