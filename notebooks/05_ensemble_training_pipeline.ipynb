{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6182fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import os, glob\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from cutmix.cutmix import CutMix\n",
    "#from cutmix.utils import CutMixCrossEntropyLoss\n",
    "\n",
    "from utils.models import get_model\n",
    "from utils.data import CustomImageDataset\n",
    "from utils.log import TextDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f53acd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4 \n",
    "RESUME = False\n",
    "epochs = 10\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 8\n",
    "WEIGHTS_DIR = \"../weights\"\n",
    "CUTMIX = False\n",
    "\n",
    "TRAIN_DATASET = \"/home/david/Documents/Datasets/train_test_classification_quarter_size/train\"\n",
    "VALID_DATASET = \"/home/david/Documents/Datasets/train_test_classification_quarter_size/valid\"\n",
    "\n",
    "Path(WEIGHTS_DIR).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e1c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, Lambda\n",
    "from torchvision.transforms import ColorJitter, RandomAffine, RandomPerspective, RandomRotation, RandomErasing, RandomCrop, Grayscale\n",
    "from torchvision.transforms import RandomChoice, RandomApply\n",
    "\n",
    "def get_train_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        RandomApply([\n",
    "            ColorJitter(brightness=0.3, contrast=0.01, saturation=0.01, hue=0),\n",
    "            RandomAffine(0.1, translate=(0.04,0.04), scale=(0.04,0.04), shear=0.01, resample=2),\n",
    "            RandomCrop(30),\n",
    "            RandomPerspective(0.1)\n",
    "        ]),\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "def get_test_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "\n",
    "def show_confusion_matrix(matrix: List[List], labels: List[str]):\n",
    "    \"\"\"Display a nice confusion matrix given\n",
    "    the confusion matrix in a 2D list + list of labels (decoder)\n",
    "    \n",
    "    Args:\n",
    "        matrix: 2D array containing the values to display (confusion matrix)\n",
    "        labels: Array containing the labels (indexed by corresponding label idx)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    min_val, max_val = 0, len(labels)\n",
    "\n",
    "    for i in range(max_val):\n",
    "        for j in range(max_val):\n",
    "            c = matrix[i][j]\n",
    "            ax.text(i, j, str(int(c)), va='center', ha='center')\n",
    "\n",
    "    ax.matshow(matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "    # Set number of ticks for x-axis\n",
    "    ax.set_xticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_xticklabels(labels, rotation='vertical', fontsize=16)\n",
    "\n",
    "    # Set number of ticks for x-axis\n",
    "    ax.set_yticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_yticklabels(labels, rotation='horizontal', fontsize=16)\n",
    "                    \n",
    "    #ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(max_val - 0.5, min_val - 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "def display_missclassified(class_to_idx: Dict[str,int], \n",
    "                           targets: List[int], \n",
    "                           predictions: List[int], \n",
    "                           images: List[np.ndarray], \n",
    "                           gridsize: Tuple[int] = (4,4)):\n",
    "    \"\"\"Display a grid with missclassified samples from test set.\n",
    "    \n",
    "    Args:\n",
    "        class_to_idx: Class to idx encoder\n",
    "        targets:      List containing all ground truths\n",
    "        predictions:  List containing all predictions\n",
    "        images:       List containing image arrays\n",
    "        gridsize:     Tuple describing the final image grid\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plot_counter = 1\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    idx_to_class = {i:label for i, label in enumerate(class_to_idx)}\n",
    "    for i in range(len(targets)):\n",
    "        if plot_counter > gridsize[0]*gridsize[1]:\n",
    "            break\n",
    "        \n",
    "        image = images[i].transpose(1, 2, 0)\n",
    "        image = ((image * std) + mean) * 255\n",
    "        image = image.astype(\"uint8\")\n",
    "    \n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = cv2.putText(image, idx_to_class[predictions[i]], (0,20), 3, 0.4, (0,0,255), 1)\n",
    "        if predictions[i] == targets[i]:\n",
    "            pass\n",
    "        else:\n",
    "            ax = fig.add_subplot(gridsize[0], gridsize[1], plot_counter)\n",
    "            ax.imshow(image)\n",
    "            plot_counter += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e810dc-698f-4cd6-b4e6-c54a913a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, device, accumulate_steps=1):\n",
    "    model.train()\n",
    "    results = {\n",
    "        \"running_loss\": 0\n",
    "    }\n",
    "    t = tqdm(train_dataloader)\n",
    "    for i, (X, y) in enumerate(t):\n",
    "        \n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        results[\"running_loss\"] += loss.cpu().detach()\n",
    "        loss = loss/accumulate_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if ((i+1) % accumulate_steps) == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        t.set_description(f\"{epoch+1}/{epochs} Train: {round(float(running_loss)/(i+1), 4)}\")\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_model(model, valid_dataloader, device, save_images=False):\n",
    "    results = {\n",
    "        \"running_loss\": 0,\n",
    "        \"targets\": list(),\n",
    "        \"predictions\": list()\n",
    "    }    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if save_images:\n",
    "            results[\"images\"] = list() \n",
    "            \n",
    "        t = tqdm(valid_dataloader)\n",
    "        for i, (X, y) in enumerate(t):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            preds = model(X)\n",
    "            results[\"predictions\"] += list(preds.argmax(axis=1).cpu().detach().numpy())\n",
    "            results[\"targets\"] += list(np.array(y.cpu()))\n",
    "            if save_images:\n",
    "                results[\"images\"] += list(np.array(X.cpu()))\n",
    "        \n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            running_loss += loss.cpu().detach()\n",
    "            t.set_description(f\"Test: {round(float(running_loss/(i+1)), 4)}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "def calculate_metrics():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e284819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = glob.glob(TRAIN_DATASET)\n",
    "valid_imgs = glob.glob(VALID_DATASET)\n",
    "\n",
    "train_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in train_imgs])\n",
    "valid_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in valid_imgs])\n",
    "class_to_idx = {label: idx for idx, label in enumerate(train_labels)}\n",
    "\n",
    "train_dataset = CustomImageDataset(train_imgs, get_test_grayscale_transforms(IMG_SIZE), train_labels)\n",
    "if CUTMIX:\n",
    "    train_dataset = CutMix(train_dataset, num_class=NUM_CLASSES, beta=1.0, prob=0.5, num_mix=3)    # this is paper's original setting for cifar.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = CustomImageDataset(valid_imgs, get_test_grayscale_transforms(IMG_SIZE), valid_labels)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50fc26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3080\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-57cd158e1555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model = get_model(model_name, NUM_CLASSES, 1\n\u001b[0m\u001b[1;32m     12\u001b[0m                  )\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# Using gpu or not\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"Using CPU\")\n",
    "    \n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, NUM_CLASSES, 1)\n",
    "    model.to(device)\n",
    "    print(list(class_to_idx.keys()))\n",
    "\n",
    "    if RESUME:\n",
    "        optimizer, criterion = get_training_stuff(model)\n",
    "    else:\n",
    "        #weights = torch.Tensor(weights).to(device)\n",
    "        #optimizer, criterion = get_training_stuff(model, weights=weights)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        if CUTMIX:\n",
    "            criterion = CutMixCrossEntropyLoss(True)\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    if RESUME:\n",
    "        start_epoch = state_dict[\"epoch\"]\n",
    "        optimizer_state_dict = state_dict[\"optimizer_state_dict\"]\n",
    "        best_test_f1 = state_dict[\"best_test_f1\"]\n",
    "\n",
    "        model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        best_test_f1 = 0\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        # Train one epoch    \n",
    "        results = train_one_epoch(model, train_dataloader, device, accumulate_steps=ACCUM_STEPS)\n",
    "        train_loss = float(results[\"running_loss\"]/(i+1))\n",
    "\n",
    "\n",
    "        if epoch+1 == epochs:\n",
    "            results = evaluate_model(model, valid_dataloader, device, save_images=True)\n",
    "            images = results[\"images\"]\n",
    "        else:\n",
    "            results = evaluate_model(model, save_images=False)\n",
    "\n",
    "        valid_loss = float(results[\"running_loss\"]/(i+1))\n",
    "        acc = accuracy_score(results[\"targets\"], results[\"predictions\"])\n",
    "        f1 = f1_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        recall = recall_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        precision = precision_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "\n",
    "    \n",
    "        if f1 > best_test_f1:\n",
    "            best_test_f1 = f1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_test_f1': best_test_f1,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, \"best.pt\"))\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_test_f1': best_test_f1,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'test_dataloader': valid_dataloader,\n",
    "        'class_to_idx': class_to_idx,\n",
    "    }, os.path.join(WEIGHTS_DIR, \"last.pt\"))\n",
    "\n",
    "    display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "    show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
