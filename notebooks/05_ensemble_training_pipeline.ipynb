{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6182fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import os, glob\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from cutmix.cutmix import CutMix\n",
    "#from cutmix.utils import CutMixCrossEntropyLoss\n",
    "\n",
    "from utils.models import get_model\n",
    "from utils.data import CustomImageDataset\n",
    "from utils.log import TextDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53acd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4 \n",
    "RESUME = False\n",
    "epochs = 10\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 4\n",
    "ACCUM_STEPS = 16\n",
    "WEIGHTS_DIR = \"../weights\"\n",
    "CUTMIX = False\n",
    "model_names = [\"resnet50\", \"cspresnet50\", \"efficientnet_b1\", \"dpn68\", \"dpn68\"]\n",
    "\n",
    "TRAIN_DATASET = \"../../../Dataset/Covid19/train_test_classification_quarter_size/train\"\n",
    "VALID_DATASET = \"../../../Dataset/Covid19/train_test_classification_quarter_size/valid\"\n",
    "\n",
    "TRAIN_DATASET += \"/*/*.jpg\"\n",
    "VALID_DATASET += \"/*/*.jpg\"\n",
    "Path(WEIGHTS_DIR).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e1c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, Lambda\n",
    "from torchvision.transforms import ColorJitter, RandomAffine, RandomPerspective, RandomRotation, RandomErasing, RandomCrop, Grayscale\n",
    "from torchvision.transforms import RandomChoice, RandomApply\n",
    "\n",
    "def get_train_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        RandomApply([\n",
    "            ColorJitter(brightness=0.3, contrast=0.01, saturation=0.01, hue=0),\n",
    "            RandomAffine(0.1, translate=(0.04,0.04), scale=(0.04,0.04), shear=0.01, resample=2),\n",
    "            RandomCrop(30),\n",
    "            RandomPerspective(0.1)\n",
    "        ]),\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "def get_test_grayscale_transforms(img_size: int) -> Compose:\n",
    "    \"\"\"Returns data transformations/augmentations for train dataset.\n",
    "    \n",
    "    Args:\n",
    "        img_size: The resolution of the input image (img_size x img_size)\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        Resize([img_size, img_size], interpolation=3),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.5203580774185134],\n",
    "            std=[0.24102417452995067])\n",
    "    ])\n",
    "\n",
    "def show_confusion_matrix(matrix: List[List], labels: List[str]):\n",
    "    \"\"\"Display a nice confusion matrix given\n",
    "    the confusion matrix in a 2D list + list of labels (decoder)\n",
    "    \n",
    "    Args:\n",
    "        matrix: 2D array containing the values to display (confusion matrix)\n",
    "        labels: Array containing the labels (indexed by corresponding label idx)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    min_val, max_val = 0, len(labels)\n",
    "\n",
    "    for i in range(max_val):\n",
    "        for j in range(max_val):\n",
    "            c = matrix[i][j]\n",
    "            ax.text(i, j, str(int(c)), va='center', ha='center')\n",
    "\n",
    "    ax.matshow(matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "    # Set number of ticks for x-axis\n",
    "    ax.set_xticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_xticklabels(labels, rotation='vertical', fontsize=16)\n",
    "\n",
    "    # Set number of ticks for x-axis\n",
    "    ax.set_yticks(np.arange(max_val))\n",
    "    # Set ticks labels for x-axis\n",
    "    ax.set_yticklabels(labels, rotation='horizontal', fontsize=16)\n",
    "                    \n",
    "    #ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(max_val - 0.5, min_val - 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "def display_missclassified(class_to_idx: Dict[str,int], \n",
    "                           targets: List[int], \n",
    "                           predictions: List[int], \n",
    "                           images: List[np.ndarray], \n",
    "                           gridsize: Tuple[int] = (4,4)):\n",
    "    \"\"\"Display a grid with missclassified samples from test set.\n",
    "    \n",
    "    Args:\n",
    "        class_to_idx: Class to idx encoder\n",
    "        targets:      List containing all ground truths\n",
    "        predictions:  List containing all predictions\n",
    "        images:       List containing image arrays\n",
    "        gridsize:     Tuple describing the final image grid\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plot_counter = 1\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    idx_to_class = {i:label for i, label in enumerate(class_to_idx)}\n",
    "    for i in range(len(targets)):\n",
    "        if plot_counter > gridsize[0]*gridsize[1]:\n",
    "            break\n",
    "        \n",
    "        image = images[i].transpose(1, 2, 0)\n",
    "        image = ((image * std) + mean) * 255\n",
    "        image = image.astype(\"uint8\")\n",
    "    \n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = cv2.putText(image, idx_to_class[predictions[i]], (0,20), 3, 0.4, (0,0,255), 1)\n",
    "        if predictions[i] == targets[i]:\n",
    "            pass\n",
    "        else:\n",
    "            ax = fig.add_subplot(gridsize[0], gridsize[1], plot_counter)\n",
    "            ax.imshow(image)\n",
    "            plot_counter += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e810dc-698f-4cd6-b4e6-c54a913a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, device, accumulate_steps=1):\n",
    "    model.train()\n",
    "    results = {\n",
    "        \"running_loss\": 0\n",
    "    }\n",
    "    t = tqdm(train_dataloader)\n",
    "    for i, (X, y) in enumerate(t):\n",
    "        \n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        results[\"running_loss\"] += loss.cpu().detach()\n",
    "        loss = loss/accumulate_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if ((i+1) % accumulate_steps) == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        t.set_description(f\"{epoch+1}/{epochs} Train: {round(float(results['running_loss'])/(i+1), 4)}\")\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_model(model, valid_dataloader, device, save_images=False):\n",
    "    results = {\n",
    "        \"running_loss\": 0,\n",
    "        \"targets\": list(),\n",
    "        \"predictions\": list()\n",
    "    }    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if save_images:\n",
    "            results[\"images\"] = list() \n",
    "            \n",
    "        t = tqdm(valid_dataloader)\n",
    "        for i, (X, y) in enumerate(t):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            preds = model(X)\n",
    "            results[\"predictions\"] += list(preds.argmax(axis=1).cpu().detach().numpy())\n",
    "            results[\"targets\"] += list(np.array(y.cpu()))\n",
    "            if save_images:\n",
    "                results[\"images\"] += list(np.array(X.cpu()))\n",
    "        \n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            running_loss += loss.cpu().detach()\n",
    "            t.set_description(f\"Test: {round(float(running_loss/(i+1)), 4)}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "def calculate_metrics():\n",
    "    pass\n",
    "\n",
    "class TrainingResults():\n",
    "    \n",
    "    def __init__(self, metrics):\n",
    "        best_results = {metric: 1e99 for metric in metrics}\n",
    "    \n",
    "    def isBest(self, metric, value):\n",
    "        if best_results[metric] < value:\n",
    "            best_results[metric] = value\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def loadCheckpoint(self, checkpoint):\n",
    "        best_results = checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e284819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'typical': 0, 'indeterminate': 1, 'atypical': 2, 'negative': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SEFuDA\\.conda\\envs\\siimcovid19\\lib\\site-packages\\torchvision\\transforms\\transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_imgs = glob.glob(TRAIN_DATASET)\n",
    "valid_imgs = glob.glob(VALID_DATASET)\n",
    "\n",
    "train_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in train_imgs])\n",
    "valid_labels = set([os.path.basename(os.path.dirname(img_path)) for img_path in valid_imgs])\n",
    "class_to_idx = {label: idx for idx, label in enumerate(train_labels)}\n",
    "\n",
    "train_dataset = CustomImageDataset(train_imgs, get_test_grayscale_transforms(IMG_SIZE), train_labels)\n",
    "if CUTMIX:\n",
    "    train_dataset = CutMix(train_dataset, num_class=NUM_CLASSES, beta=1.0, prob=0.5, num_mix=3)    # this is paper's original setting for cifar.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = CustomImageDataset(valid_imgs, get_test_grayscale_transforms(IMG_SIZE), valid_labels)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fc26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['typical', 'indeterminate', 'atypical', 'negative']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SEFuDA\\.conda\\envs\\siimcovid19\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "1/10 Train: 1.1239: 100%|██████████████████████████████████████████████████████████| 1334/1334 [04:56<00:00,  4.50it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-716c20932fba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# Train one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccumulate_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mACCUM_STEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"running_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# Using gpu or not\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"Using CPU\")\n",
    "    \n",
    "for model_name in model_names:\n",
    "    model = get_model(model_name, NUM_CLASSES, 1)\n",
    "    model.to(device)\n",
    "    print(list(class_to_idx.keys()))\n",
    "\n",
    "    results = TextDocument(f\"{model_name}_results.txt\")\n",
    "    results.add_line(f\"acc f1 recall precision valid_loss train_loss\") \n",
    "    metrics = [\"acc\", \"f1\", \"valid_loss\"]\n",
    "    training_results = TrainingResults(metrics)\n",
    "    if RESUME:\n",
    "        pass\n",
    "        #start_epoch = state_dict[\"epoch\"]\n",
    "        #optimizer_state_dict = state_dict[\"optimizer_state_dict\"]\n",
    "        \n",
    "        #model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "        #optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
    "        training_results.loadCheckpoint(state_dict[\"training_results\"])\n",
    "    else:\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        if CUTMIX:\n",
    "            criterion = CutMixCrossEntropyLoss(True)\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        # Train one epoch    \n",
    "        results = train_one_epoch(model, train_dataloader, device, accumulate_steps=ACCUM_STEPS)\n",
    "        train_loss = float(results[\"running_loss\"]/(i+1))\n",
    "\n",
    "\n",
    "        if epoch+1 == epochs:\n",
    "            results = evaluate_model(model, valid_dataloader, device, save_images=True)\n",
    "            images = results[\"images\"]\n",
    "        else:\n",
    "            results = evaluate_model(model, save_images=False)\n",
    "\n",
    "        valid_loss = float(results[\"running_loss\"]/(i+1))\n",
    "        acc = accuracy_score(results[\"targets\"], results[\"predictions\"])\n",
    "        f1 = f1_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        recall = recall_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        precision = precision_score(results[\"targets\"], results[\"predictions\"], average=\"macro\", labels=np.unique(results[\"predictions\"]))\n",
    "        results.add_line(f\"{float(acc)} {float(f1)} {float(recall)} {float(precision)} {valid_loss} {train_loss}\")\n",
    "    \n",
    "        training_results.isBest('f1',f1)\n",
    "        if training_results.isBest('f1',f1):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_test_f1': best_test_f1,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}_best_f1.pt\"))\n",
    "        if training_results.isBest('acc',acc):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_test_f1': best_test_f1,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}_best_acc.pt\"))\n",
    "        if training_results.isBest('valid_loss',valid_loss):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_test_f1': best_test_f1,\n",
    "                'train_dataloader': train_dataloader,\n",
    "                'test_dataloader': valid_dataloader,\n",
    "                'class_to_idx': class_to_idx\n",
    "            }, os.path.join(WEIGHTS_DIR, f\"{model_name}_best_valid_loss.pt\"))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_test_f1': best_test_f1,\n",
    "            'train_dataloader': train_dataloader,\n",
    "            'test_dataloader': valid_dataloader,\n",
    "            'class_to_idx': class_to_idx\n",
    "        }, os.path.join(WEIGHTS_DIR, f\"{model_name}_last.pt\"))\n",
    "\n",
    "    display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "    show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missclassified(class_to_idx, targets, predictions, images, gridsize=(4,4))\n",
    "show_confusion_matrix(confusion_matrix(targets, predictions), list(class_to_idx.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0f6a2-4693-4fcc-b9eb-e865dcecb81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af46f4d-cb72-43b5-b89f-455eb4bf1419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
